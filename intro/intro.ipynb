{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API Call Example\n",
    "\n",
    "This notebook demonstrates how to make a simple call to the OpenAI API to generate text using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "source": [
    "!pip install openai\n",
    "!pip install python-dotenv"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T12:28:26.274527Z",
     "start_time": "2024-03-23T12:28:24.016637Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "  What is chat-gpt??\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  messages=[        \n",
    "         {\"role\": \"user\", \"content\": f\"{user_prompt}\"},\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat-GPT is a conversational AI model developed by OpenAI that is designed to generate human-like responses in natural language conversations. It is based on the GPT-3 (Generative Pre-trained Transformer 3) model and is trained on a large dataset of text from the internet to generate coherent and contextually relevant responses to user inputs. Chat-GPT can be used in a variety of applications, such as chatbots, virtual assistants, and customer service interactions.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Open AI - API Parameters explanation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in April 2023, when using the OpenAI API, particularly for the ChatGPT or similar models, you interact with the API by sending HTTP requests. The documentation you referred to provides detailed information on how to use the API, including the various parameters you can set to customize the behavior of the model. Below, I'll explain some of the key parameters you might use for a chat or conversational model based on the OpenAI API documentation available at that time. Please note that the exact parameters and their functionalities might evolve, so it's always a good idea to check the latest documentation for the most current information.\n",
      "\n",
      "### Model\n",
      "\n",
      "- **`model`**: This parameter specifies which version of the model you want to use (e.g., `gpt-3.5-turbo`, `davinci`, etc.). The choice of model affects the quality of the responses, as well as the cost per request.\n",
      "\n",
      "### Messages\n",
      "\n",
      "- **`messages`**: This is a list of message objects representing the conversation history. Each message object can have the following keys:\n",
      "  - **`role`**: Indicates whether the message is from the `system`, `user`, or `assistant`. The `system` role can be used for providing instructions to the model.\n",
      "  - **`content`**: The text of the message.\n",
      "\n",
      "### Temperature\n",
      "\n",
      "- **`temperature`**: This parameter controls the randomness of the model's responses. A higher temperature results in more varied responses, while a lower temperature makes the model's responses more deterministic. The value ranges from 0 to 1.\n",
      "\n",
      "### Max Tokens\n",
      "\n",
      "- **`max_tokens`**: This sets the maximum length of the model's response, measured in tokens (words and punctuation marks). Adjusting this can help control the verbosity of the response.\n",
      "\n",
      "### Top P\n",
      "\n",
      "- **`top_p`**: This parameter, also known as nucleus sampling, controls the diversity of the model's responses by limiting the token selection pool to the most probable tokens. A value closer to 1.0 results in more diversity.\n",
      "\n",
      "### Frequency Penalty\n",
      "\n",
      "- **`frequency_penalty`**: This adjusts the likelihood of the model repeating the same line verbatim, with higher values making repetitions less likely.\n",
      "\n",
      "### Presence Penalty\n",
      "\n",
      "- **`presence_penalty`**: This influences the model to introduce new topics into the conversation, with higher values encouraging more novel content.\n",
      "\n",
      "### Stop Sequences\n",
      "\n",
      "- **`stop`**: You can specify an array of strings that, when detected in the model's output, will cause the model to stop generating further tokens. This is useful for defining natural endpoints to responses.\n",
      "\n",
      "### User\n",
      "\n",
      "- **`user`**: An optional parameter that can be used to specify the user ID associated with the request. This can be useful for logging or personalization purposes.\n",
      "\n",
      "### Other Parameters\n",
      "\n",
      "There are other parameters you might find useful depending on your specific use case, such as `logprobs` for getting the probabilities of specific tokens, or `best_of` for generating multiple responses and choosing the best one.\n",
      "\n",
      "### Example Request\n",
      "\n",
      "Here's a simplified example of how you might structure a request in Python using the `requests` library:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "\n",
      "api_url = \"https://api.openai.com/v1/chat/completions\"\n",
      "headers = {\n",
      "    \"Authorization\": \"Bearer YOUR_API_KEY\",\n",
      "    \"Content-Type\": \"application/json\",\n",
      "}\n",
      "\n",
      "data = {\n",
      "    \"model\": \"gpt-3.5-turbo\",\n",
      "    \"messages\": [\n",
      "        {\"role\": \"user\", \"content\": \"Hello, who won the world series in 2020?\"},\n",
      "    ],\n",
      "    \"temperature\": 0.5,\n",
      "    \"max_tokens\": 100,\n",
      "}\n",
      "\n",
      "response = requests.post(api_url, headers=headers, json=data)\n",
      "print(response.json())\n",
      "```\n",
      "\n",
      "Remember to replace `\"YOUR_API_KEY\"` with your actual OpenAI API key. This example sends a simple query to the model and prints out the response.\n",
      "\n",
      "Always refer to the latest OpenAI API documentation for the most accurate and up-to-date information.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "  I'm learning openAI api, could you explain how to use the parameters for usage? You can find the documentation at https://platform.openai.com/docs/api-reference/chat\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  messages=[        \n",
    "         {\"role\": \"user\", \"content\": f\"{user_prompt}\"},\n",
    "    ],\n",
    "    model=\"gpt-4-0125-preview\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T12:39:19.761307Z",
     "start_time": "2024-03-23T12:38:45.260884Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
